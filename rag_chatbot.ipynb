{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # to access environment variables\n",
    "from dotenv import load_dotenv # to load .env file\n",
    "\n",
    "import openai\n",
    "import langchain\n",
    "import pinecone \n",
    "\n",
    "# Data loading and text splitting\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# --- Core LangChain Components ---\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "# Embeddings and LLMs\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "# Pinecone and LangChain integration\n",
    "from langchain_pinecone import PineconeVectorStore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the document\n",
    "def read_doc(directory):\n",
    "    file_loader=PyPDFDirectoryLoader(directory)\n",
    "    documents=file_loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc=read_doc('/Users/sivamanipatnala/Downloads/RAG_Chatbot/documents/')\n",
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divide the docs into chunks\n",
    "def chunk_data(docs,chunk_size=800,chunk_overlap=50):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size,chunk_overlap=chunk_overlap)\n",
    "    chunked_doc=text_splitter.split_documents(docs)\n",
    "    return chunked_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_doc=chunk_data(docs=doc)\n",
    "len(chunked_doc)\n",
    "# length is increased from 58 because of chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nload_dotenv(override=True) \\n'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "load_dotenv(override=True) \n",
    "\"\"\"\n",
    "# changing api key in .env file and saving doesnt override undeless the above command is run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x1101f9480>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x1101fb130>, model='text-embedding-3-small', dimensions=None, deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding Technique Of OPENAI\n",
    "# Initialize embeddings\n",
    "load_dotenv()\n",
    "embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector search DB in Pinecone\n",
    "\"\"\" This single step connects to Pinecone, creates embeddings for your documents,\n",
    "    and stores them in the specified index. Pass chunked data, not raw data. \"\"\"\n",
    "\n",
    "index_name = \"langchainvector\"\n",
    "\n",
    "vectorstore = PineconeVectorStore.from_documents(\n",
    "    documents=chunked_doc, \n",
    "    embedding=embeddings, \n",
    "    index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rag_chain(vectorstore):\n",
    "    # Create rag chain using LCEL (LangChain Expression Language)\n",
    "    llm = ChatOpenAI(model=\"gpt-5-nano\", temperature=0.5)\n",
    "    retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})\n",
    "\n",
    "    template = \"\"\"\n",
    "    You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. \n",
    "    If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "    Context: {context} \n",
    "\n",
    "    Question: {question} \n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    \n",
    "    rag_chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    print(\"RAG chain created successfully.\")\n",
    "    return rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG chain created successfully.\n"
     ]
    }
   ],
   "source": [
    "qa_chain = create_rag_chain(vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pradhan Mantri Kaushal Vikas Yojana 4.0 (PMKVY 4.0) will be launched to skill lakhs of youth and enhance their employability.\n"
     ]
    }
   ],
   "source": [
    "our_query = \"Which skill will be launched by government to create employability and train youth?\"\n",
    "answer = qa_chain.invoke(our_query)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents...\n",
      "Loaded 58 document(s).\n",
      "Splitting documents into chunks...\n",
      "Split into 119 chunks.\n",
      "Creating/updating Pinecone vector store 'langchainvector'...\n",
      "Vector store is ready.\n",
      "Creating RAG chain...\n",
      "RAG chain created successfully.\n",
      "\n",
      "Querying the chain with: 'How much the agriculture target will be increased by how many crore?'\n",
      "\n",
      "--- Answer ---\n",
      "The agriculture credit target will be increased to â‚¹20 lakh crore.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- Document Loading and Splitting ---\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# --- Core LangChain Components ---\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# --- Integrations ---\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# 1. Load Environment Variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# --- DATA INGESTION AND PROCESSING ---\n",
    "\n",
    "def load_documents(directory='documents/'):\n",
    "    \"\"\"Loads PDF documents from a specified directory.\"\"\"\n",
    "    print(\"Loading documents...\")\n",
    "    loader = PyPDFDirectoryLoader(directory)\n",
    "    documents = loader.load()\n",
    "    print(f\"Loaded {len(documents)} document(s).\")\n",
    "    return documents\n",
    "\n",
    "def split_documents(documents):\n",
    "    \"\"\"Splits documents into smaller chunks.\"\"\"\n",
    "    print(\"Splitting documents into chunks...\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    chunked_documents = text_splitter.split_documents(documents)\n",
    "    print(f\"Split into {len(chunked_documents)} chunks.\")\n",
    "    return chunked_documents\n",
    "\n",
    "# --- VECTOR STORE SETUP ---\n",
    "\n",
    "def setup_vectorstore(chunked_documents):\n",
    "    \"\"\"Initializes Pinecone vector store and ingests documents.\"\"\"\n",
    "    index_name = \"langchainvector\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    \n",
    "    print(f\"Creating/updating Pinecone vector store '{index_name}'...\")\n",
    "    # This will create embeddings and upload them to Pinecone\n",
    "    # If the index already exists, it will be updated with the new documents\n",
    "    vectorstore = PineconeVectorStore.from_documents(\n",
    "        documents=chunked_documents,\n",
    "        embedding=embeddings,\n",
    "        index_name=index_name\n",
    "    )\n",
    "    print(\"Vector store is ready.\")\n",
    "    return vectorstore\n",
    "\n",
    "# --- RAG CHAIN SETUP ---\n",
    "\n",
    "def create_rag_chain(vectorstore):\n",
    "    \"\"\"Creates a RAG chain using LCEL.\"\"\"\n",
    "    print(\"Creating RAG chain...\")\n",
    "    \n",
    "    # Initialize the latest OpenAI model\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "    \n",
    "    # Create a retriever to fetch relevant documents from the vector store\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    # Define the prompt template\n",
    "    template = \"\"\"\n",
    "    You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. \n",
    "    If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "    Context: {context} \n",
    "\n",
    "    Question: {question} \n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # Create the RAG chain using LangChain Expression Language (LCEL)\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    print(\"RAG chain created successfully.\")\n",
    "    return rag_chain\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Step 1: Load and process the documents\n",
    "    docs = load_documents()\n",
    "    chunks = split_documents(docs)\n",
    "    \n",
    "    # Step 2: Setup the vector store\n",
    "    vector_store = setup_vectorstore(chunks)\n",
    "    \n",
    "    # Step 3: Create the RAG chain\n",
    "    qa_chain = create_rag_chain(vector_store)\n",
    "    \n",
    "    # Step 4: Ask a question\n",
    "    query = \"How much the agriculture target will be increased by how many crore?\"\n",
    "    print(f\"\\nQuerying the chain with: '{query}'\")\n",
    "    answer = qa_chain.invoke(query)\n",
    "    \n",
    "    print(\"\\n--- Answer ---\")\n",
    "    print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
