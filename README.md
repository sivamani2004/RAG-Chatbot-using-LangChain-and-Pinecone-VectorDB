# RAG-Chatbot-using-LangChain-and-Pinecone-VectorDB
Creates a Q&amp;A RAG Chain that learns a document and answers queries, using LangChain and Pinecone Vector Database.

This project is a complete Retrieval-Augmented Generation (RAG) pipeline built with Python. It allows you to chat with your own PDF documents by leveraging the power of Large Language Models (LLMs) and vector databases. The application ingests a collection of PDFs, processes them into a searchable format, and uses this knowledge base to answer user questions.

# Features

- Chat with Your Data: Ask questions in natural language about the content of your PDF documents.
- Efficient Search: Uses Pinecone's serverless vector database for fast and scalable similarity searches.
- State-of-the-Art AI: Employs OpenAI's latest models (gpt-4o and text-embedding-3-small) for high-quality answers and embeddings.
- Modern Framework: Built with the latest version of LangChain, using the powerful and flexible LangChain Expression Language (LCEL).

Create Pinecone VectorDB from website and get LangChain and OpenAI API keys.
